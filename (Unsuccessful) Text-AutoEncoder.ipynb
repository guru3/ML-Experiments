{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_source = 'https://www.kaggle.com/jrobischon/wikipedia-movie-plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '/Users/gursharan/Desktop/wiki_movie_plots_deduped.csv'\n",
    "input_length = 500\n",
    "compressed_length = 300\n",
    "\n",
    "data_reader = csv.reader(open(data_file,'r'))\n",
    "next(data_reader) #skip the header\n",
    "text_corpus = []\n",
    "for row in data_reader:\n",
    "    plot = row[-1].upper() #upper case only\n",
    "    \n",
    "    text = []\n",
    "    plot_index = 0\n",
    "    while( plot_index < len(plot) and len(text) < input_length ):\n",
    "        char = plot[ plot_index ]\n",
    "        #limit to \n",
    "        if( ord(char) < 128 ):\n",
    "            text.append(char)\n",
    "        plot_index = plot_index + 1\n",
    "    \n",
    "    plot = ' '.join((''.join(text)).split()[:-1])\n",
    "    if len(plot) < input_length:\n",
    "        plot = plot + ' '*(input_length-len(plot)) #padded by space at last\n",
    "        \n",
    "    text_corpus.append(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASTING JUST 61 SECONDS AND CONSISTING OF TWO SHOTS, THE FIRST SHOT IS SET IN A WOOD DURING WINTER. THE ACTOR REPRESENTING THEN VICE-PRESIDENT THEODORE ROOSEVELT ENTHUSIASTICALLY HURRIES DOWN A HILLSIDE TOWARDS A TREE IN THE FOREGROUND. HE FALLS ONCE, BUT RIGHTS HIMSELF AND COCKS HIS RIFLE. TWO OTHER MEN, BEARING SIGNS READING \"HIS PHOTOGRAPHER\" AND \"HIS PRESS AGENT\" RESPECTIVELY, FOLLOW HIM INTO THE SHOT; THE PHOTOGRAPHER SETS UP HIS CAMERA. \"TEDDY\" AIMS HIS RIFLE UPWARD AT THE TREE AND FELLS  \n"
     ]
    }
   ],
   "source": [
    "print(text_corpus[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_numbers( text ):\n",
    "    array = []\n",
    "    for char in text:\n",
    "        array.append( ord(char) )\n",
    "    return np.array(array)\n",
    "\n",
    "def numbers_to_text( array ):\n",
    "    text = []\n",
    "    for number in array:\n",
    "        text.append( chr(number) )\n",
    "    return ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76 65 83 84 73 78 71 32 74 85 83 84 32 54 49 32 83 69 67 79 78 68 83 32\n",
      " 65 78 68 32 67 79 78 83 73 83 84 73 78 71 32 79 70 32 84 87 79 32 83 72\n",
      " 79 84 83 44 32 84 72 69 32 70 73 82 83 84 32 83 72 79 84 32 73 83 32 83\n",
      " 69 84 32 73 78 32 65 32 87 79 79 68 32 68 85 82 73 78 71 32 87 73 78 84\n",
      " 69 82 46 32 84 72 69 32 65 67 84 79 82 32 82 69 80 82 69 83 69 78 84 73\n",
      " 78 71 32 84 72 69 78 32 86 73 67 69 45 80 82 69 83 73 68 69 78 84 32 84\n",
      " 72 69 79 68 79 82 69 32 82 79 79 83 69 86 69 76 84 32 69 78 84 72 85 83\n",
      " 73 65 83 84 73 67 65 76 76 89 32 72 85 82 82 73 69 83 32 68 79 87 78 32\n",
      " 65 32 72 73 76 76 83 73 68 69 32 84 79 87 65 82 68 83 32 65 32 84 82 69\n",
      " 69 32 73 78 32 84 72 69 32 70 79 82 69 71 82 79 85 78 68 46 32 72 69 32\n",
      " 70 65 76 76 83 32 79 78 67 69 44 32 66 85 84 32 82 73 71 72 84 83 32 72\n",
      " 73 77 83 69 76 70 32 65 78 68 32 67 79 67 75 83 32 72 73 83 32 82 73 70\n",
      " 76 69 46 32 84 87 79 32 79 84 72 69 82 32 77 69 78 44 32 66 69 65 82 73\n",
      " 78 71 32 83 73 71 78 83 32 82 69 65 68 73 78 71 32 34 72 73 83 32 80 72\n",
      " 79 84 79 71 82 65 80 72 69 82 34 32 65 78 68 32 34 72 73 83 32 80 82 69\n",
      " 83 83 32 65 71 69 78 84 34 32 82 69 83 80 69 67 84 73 86 69 76 89 44 32\n",
      " 70 79 76 76 79 87 32 72 73 77 32 73 78 84 79 32 84 72 69 32 83 72 79 84\n",
      " 59 32 84 72 69 32 80 72 79 84 79 71 82 65 80 72 69 82 32 83 69 84 83 32\n",
      " 85 80 32 72 73 83 32 67 65 77 69 82 65 46 32 34 84 69 68 68 89 34 32 65\n",
      " 73 77 83 32 72 73 83 32 82 73 70 76 69 32 85 80 87 65 82 68 32 65 84 32\n",
      " 84 72 69 32 84 82 69 69 32 65 78 68 32 70 69 76 76 83 32 32]\n",
      "LASTING JUST 61 SECONDS AND CONSISTING OF TWO SHOTS, THE FIRST SHOT IS SET IN A WOOD DURING WINTER. THE ACTOR REPRESENTING THEN VICE-PRESIDENT THEODORE ROOSEVELT ENTHUSIASTICALLY HURRIES DOWN A HILLSIDE TOWARDS A TREE IN THE FOREGROUND. HE FALLS ONCE, BUT RIGHTS HIMSELF AND COCKS HIS RIFLE. TWO OTHER MEN, BEARING SIGNS READING \"HIS PHOTOGRAPHER\" AND \"HIS PRESS AGENT\" RESPECTIVELY, FOLLOW HIM INTO THE SHOT; THE PHOTOGRAPHER SETS UP HIS CAMERA. \"TEDDY\" AIMS HIS RIFLE UPWARD AT THE TREE AND FELLS  \n"
     ]
    }
   ],
   "source": [
    "numbers = text_to_numbers( text_corpus[3] )\n",
    "text = numbers_to_text( numbers )\n",
    "print( numbers )\n",
    "print( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the network\n",
    "model = keras.models.Sequential()\n",
    "model.add( keras.layers.Dense(1024, activation='relu', input_shape=(input_length,)) )\n",
    "model.add( keras.layers.Dense(512, activation='relu' ))\n",
    "model.add( keras.layers.Dense(compressed_length, activation='relu' ))\n",
    "model.add( keras.layers.Dense(512, activation='relu' ))\n",
    "model.add( keras.layers.Dense(1024, activation='relu' ))\n",
    "model.add( keras.layers.Dense(input_length, activation='relu' ))\n",
    "model.compile( loss='mae', optimizer='adadelta', metrics=['mse'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data and create train, validation, test subsets\n",
    "all_data = np.array( [ text_to_numbers(x) for x in text_corpus ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = all_data/128\n",
    "data_indices = np.random.permutation(len(all_data))\n",
    "train = normalized_data[ data_indices[: int(len(all_data)*0.8) ] ]\n",
    "val = normalized_data[data_indices[int(len(all_data)*0.8):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27908 samples, validate on 6978 samples\n",
      "Epoch 1/10\n",
      "27908/27908 [==============================] - 26s 947us/step - loss: 0.2348 - mse: 0.0996 - val_loss: 0.1928 - val_mse: 0.0794\n",
      "Epoch 2/10\n",
      "27908/27908 [==============================] - 27s 954us/step - loss: 0.1850 - mse: 0.0755 - val_loss: 0.1794 - val_mse: 0.0725\n",
      "Epoch 3/10\n",
      "27908/27908 [==============================] - 28s 1ms/step - loss: 0.1766 - mse: 0.0708 - val_loss: 0.1735 - val_mse: 0.0685\n",
      "Epoch 4/10\n",
      "27908/27908 [==============================] - 27s 981us/step - loss: 0.1700 - mse: 0.0669 - val_loss: 0.1690 - val_mse: 0.0661\n",
      "Epoch 5/10\n",
      "27908/27908 [==============================] - 28s 997us/step - loss: 0.1653 - mse: 0.0640 - val_loss: 0.1637 - val_mse: 0.0628\n",
      "Epoch 6/10\n",
      "27908/27908 [==============================] - 28s 1ms/step - loss: 0.1579 - mse: 0.0594 - val_loss: 0.1544 - val_mse: 0.0572\n",
      "Epoch 7/10\n",
      "27908/27908 [==============================] - 29s 1ms/step - loss: 0.1510 - mse: 0.0552 - val_loss: 0.1514 - val_mse: 0.0540\n",
      "Epoch 8/10\n",
      "27908/27908 [==============================] - 29s 1ms/step - loss: 0.1478 - mse: 0.0532 - val_loss: 0.1470 - val_mse: 0.0522\n",
      "Epoch 9/10\n",
      "27908/27908 [==============================] - 29s 1ms/step - loss: 0.1450 - mse: 0.0515 - val_loss: 0.1442 - val_mse: 0.0509\n",
      "Epoch 10/10\n",
      "27908/27908 [==============================] - 29s 1ms/step - loss: 0.1431 - mse: 0.0505 - val_loss: 0.1445 - val_mse: 0.0510\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, train, epochs=10, validation_data=(val,val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE STORY IS PRESENTED AS A NARRATED DOCUMENTARY, SET IN A NEAR-FUTURE 1970S ENGLAND, AND CONCERNING A DISILLUSIONED POP SINGER, STEVEN SHORTER (PAUL JONES), WHO IS THE MOST-LOVED CELEBRITY IN THE COUNTRY. HIS STAGE SHOW INVOLVES HIM APPEARING ON STAGE IN A JAIL CELL WITH HANDCUFFS, BEATEN BY POLICE, TO THE HORROR AND SYMPATHY OF THE AUDIENCE. IT IS DESCRIBED THAT THE TWO MAIN PARTIES OF ENGLAND HAVE FORMED A COALITION GOVERNMENT AND ENCOURAGE THE SUCCESS OF SHORTER TO PLACATE THE MASSES AND    \n",
      "NHCCCI\u0000JEKBFJ\u0000LDL\u0000HEE\u0000GADK\u0000BJ\u0000FFE\u0000IGG\u0000IIGH\u0000JFDONDEIHEGKJG\u0000\u0000\u0000BIKHMGKEKIHBFKEFJ\u0000NAHJ\u0000DJJFDJK\u0000C\u0000GFGJDGIBHHFIIDFKDOGHGGGGLHJJI\u0000KDGHFD?LIFKGIHOHKH\u0000ID\u0000IGIGJFMICJKJHJDKGHLFJKIFCM\u0000JLKG\u0000CMMDCJGK\u0000DLLFBLHCCEF\u0000JMNIKHIGGJLDMFO\u0000\u0000FFDNPDJ\u0000DDIFGNH\u0000\u0000FF\u0000\u0000IDI@HMMJ\u0000BB\u0000FMGEELHEEIGGGJFK\u0000FOEFNHF@MG\u0000K\u0000AAQ\u0000GM\u0000\u0000GKLEGIJJBS\u0000FMIJLDEHJIIHJ\u0000\u0000EKKFINMB\u0000FIJJKGFDJLDFNF\u0000DFDII\u0000E\u0000LHE\u0000CKIHFGFILK\u0000KH\u0000FK\u0000EEKOJHKFG\u0000HIFFH\u0000LGGFNEHHJ\u0000GIKJ\u0000\u0000FHKEHGDIMKDKH@FFGKHHIFCGLHJ\u0000IHJJFFGJPDKGGK\u0000ONDJL\u0000HHMB\u0000LIKIOJDJMKMKLJ\u0000JIMOGLOIONIJMHMGMLLM\u0000QJKMOL\u0000WO/\u001f \u001d",
      "\n"
     ]
    }
   ],
   "source": [
    "random_example = text_corpus[ np.random.randint(len(text_corpus)) ]\n",
    "input_is = text_to_numbers( random_example )/128\n",
    "output_is = model.predict( input_is.reshape(1,500) )\n",
    "output_is = (output_is*128).astype('int')\n",
    "predicted_text = numbers_to_text(output_is[0])\n",
    "print(random_example)\n",
    "print(predicted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It doesn't seem to work, even the training seems too slow. I need to re-think what the loss function should be. I guess mistake was to use ordinal values for characters as it's representation - even if it ends up predicting all Es as Fs, the loss will be less. We need to define one-hot vectors so that Es and Fs are distinguished!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 200\n",
    "compressed_length = 100\n",
    "\n",
    "data_file = '/Users/gursharan/Desktop/wiki_movie_plots_deduped.csv'\n",
    "\n",
    "data_reader = csv.reader(open(data_file,'r'))\n",
    "next(data_reader) #skip the header\n",
    "text_corpus = []\n",
    "for row in data_reader:\n",
    "    plot = row[-1].upper() #upper case only\n",
    "\n",
    "    text = []\n",
    "    plot_index = 0\n",
    "    while( plot_index < len(plot) and len(text) < input_length ):\n",
    "        char = plot[ plot_index ]\n",
    "        #limit to A-Z only\n",
    "        if( char>='A' and char<='Z' ):\n",
    "            text.append(char)\n",
    "        if( char == ' '):\n",
    "            text.append('@')\n",
    "        plot_index = plot_index + 1\n",
    "    \n",
    "    plot = ''.join(text)\n",
    "    if len(plot) < input_length:\n",
    "        plot = plot + '@'*(input_length-len(plot)) #padded by space at last\n",
    "        \n",
    "    text_corpus.append(plot)\n",
    "\n",
    "def text_to_numbers( text ):\n",
    "    array = []\n",
    "    #64-90\n",
    "    for char in text:\n",
    "        val = np.zeros(27)\n",
    "        val[ord(char)-ord('@')] = 1\n",
    "        array.extend( val )\n",
    "    return np.array(array)\n",
    "\n",
    "def numbers_to_text( array ):\n",
    "    text = []\n",
    "    for total in range(input_length):\n",
    "        numbers = array[total*27:(total+1)*27]\n",
    "        text.append( chr(np.argmax(numbers)+ord('@')) )\n",
    "    return ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASTING@JUST@@SECONDS@AND@CONSISTING@OF@TWO@SHOTS@THE@FIRST@SHOT@IS@SET@IN@A@WOOD@DURING@WINTER@THE@ACTOR@REPRESENTING@THEN@VICEPRESIDENT@THEODORE@ROOSEVELT@ENTHUSIASTICALLY@HURRIES@DOWN@A@HILLSIDE@TO\n",
      "LASTING@JUST@@SECONDS@AND@CONSISTING@OF@TWO@SHOTS@THE@FIRST@SHOT@IS@SET@IN@A@WOOD@DURING@WINTER@THE@ACTOR@REPRESENTING@THEN@VICEPRESIDENT@THEODORE@ROOSEVELT@ENTHUSIASTICALLY@HURRIES@DOWN@A@HILLSIDE@TO\n"
     ]
    }
   ],
   "source": [
    "text = text_corpus[3]\n",
    "numbers = text_to_numbers(text)\n",
    "text_d = numbers_to_text(numbers)\n",
    "print(text)\n",
    "print(text_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the network\n",
    "model = keras.models.Sequential()\n",
    "model.add( keras.layers.Dense(1024, activation='relu', input_shape=(input_length*27,)) )\n",
    "model.add( keras.layers.Dense(512, activation='relu' ))\n",
    "model.add( keras.layers.Dense(compressed_length, activation='relu' ))\n",
    "model.add( keras.layers.Dense(512, activation='relu' ))\n",
    "model.add( keras.layers.Dense(1024, activation='relu' ))\n",
    "model.add( keras.layers.Dense(input_length*27, activation='relu' ))\n",
    "model.compile( loss='binary_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data and create train, validation, test subsets\n",
    "all_data = np.array( [ text_to_numbers(x) for x in text_corpus ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total examples :  34886\n",
      "total training examples :  27908\n",
      "total validation examples :  6978\n"
     ]
    }
   ],
   "source": [
    "data_indices = np.random.permutation(len(all_data))\n",
    "train = all_data[ data_indices[: int(len(all_data)*0.8) ] ]\n",
    "val = all_data[data_indices[int(len(all_data)*0.8):]]\n",
    "print('total examples : ', len(all_data))\n",
    "print('total training examples : ', len(train))\n",
    "print('total validation examples : ', len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27908 samples, validate on 6978 samples\n",
      "Epoch 1/10\n",
      "27908/27908 [==============================] - 175s 6ms/step - loss: 0.2112 - val_loss: 0.1989\n",
      "Epoch 2/10\n",
      "27908/27908 [==============================] - 171s 6ms/step - loss: 0.1977 - val_loss: 0.1968\n",
      "Epoch 3/10\n",
      "27908/27908 [==============================] - 184s 7ms/step - loss: 0.1945 - val_loss: 0.1941\n",
      "Epoch 4/10\n",
      "27908/27908 [==============================] - 178s 6ms/step - loss: 0.1917 - val_loss: 0.1909\n",
      "Epoch 5/10\n",
      "27908/27908 [==============================] - 160s 6ms/step - loss: 0.1898 - val_loss: 0.1894\n",
      "Epoch 6/10\n",
      "27908/27908 [==============================] - 191s 7ms/step - loss: 0.1876 - val_loss: 0.1902\n",
      "Epoch 7/10\n",
      "27908/27908 [==============================] - 182s 7ms/step - loss: 0.1905 - val_loss: 0.1917\n",
      "Epoch 8/10\n",
      "27908/27908 [==============================] - 184s 7ms/step - loss: 0.1920 - val_loss: 0.1962\n",
      "Epoch 9/10\n",
      "27908/27908 [==============================] - 183s 7ms/step - loss: 0.1946 - val_loss: 0.2000\n",
      "Epoch 10/10\n",
      "27908/27908 [==============================] - 160s 6ms/step - loss: 0.1979 - val_loss: 0.1979\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, train, epochs=10, validation_data=(val,val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original : LASTING@JUST@@SECONDS@AND@CONSISTING@OF@TWO@SHOTS@THE@FIRST@SHOT@IS@SET@IN@A@WOOD@DURING@WINTER@THE@ACTOR@REPRESENTING@THEN@VICEPRESIDENT@THEODORE@ROOSEVELT@ENTHUSIASTICALLY@HURRIES@DOWN@A@HILLSIDE@TO\n",
      "Predicted : THE@@@@@@M@@@@@@@@@@@@@@@@@@@@@@@@@C@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@E@@@@@@@@@@@@@@@@@@@@@EE@@@@@@@@@@E@@@@@@@@@@@@@@@@E@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "text = text_corpus[3]\n",
    "numbers = text_to_numbers(text)\n",
    "numbers = numbers.reshape(1,5400)\n",
    "output = model.predict(numbers)\n",
    "pred = numbers_to_text(output[0])\n",
    "print('Original :', text)\n",
    "print('Predicted :', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27908 samples, validate on 6978 samples\n",
      "Epoch 1/10\n",
      "27908/27908 [==============================] - 160s 6ms/step - loss: 0.1937 - val_loss: 0.1959\n",
      "Epoch 2/10\n",
      "27908/27908 [==============================] - 160s 6ms/step - loss: 0.1975 - val_loss: 0.1968\n",
      "Epoch 3/10\n",
      "27908/27908 [==============================] - 159s 6ms/step - loss: 0.1967 - val_loss: 0.1994\n",
      "Epoch 4/10\n",
      "27908/27908 [==============================] - 160s 6ms/step - loss: 0.1981 - val_loss: 0.1992\n",
      "Epoch 5/10\n",
      "27908/27908 [==============================] - 159s 6ms/step - loss: 0.2001 - val_loss: 0.1978\n",
      "Epoch 6/10\n",
      "27908/27908 [==============================] - 159s 6ms/step - loss: 0.1944 - val_loss: 0.1945\n",
      "Epoch 7/10\n",
      "27908/27908 [==============================] - 159s 6ms/step - loss: 0.1991 - val_loss: 0.2082\n",
      "Epoch 8/10\n",
      "27908/27908 [==============================] - 157s 6ms/step - loss: 0.1995 - val_loss: 0.2018\n",
      "Epoch 9/10\n",
      "27908/27908 [==============================] - 151s 5ms/step - loss: 0.2030 - val_loss: 0.2022\n",
      "Epoch 10/10\n",
      "27908/27908 [==============================] - 152s 5ms/step - loss: 0.1979 - val_loss: 0.2021\n"
     ]
    }
   ],
   "source": [
    "history_2 = model.fit(train, train, epochs=10, validation_data=(val,val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original : LASTING@JUST@@SECONDS@AND@CONSISTING@OF@TWO@SHOTS@THE@FIRST@SHOT@IS@SET@IN@A@WOOD@DURING@WINTER@THE@ACTOR@REPRESENTING@THEN@VICEPRESIDENT@THEODORE@ROOSEVELT@ENTHUSIASTICALLY@HURRIES@DOWN@A@HILLSIDE@TO\n",
      "Predicted : FN@@@@@@@@@@@@@@@@@@@@@@@@@@D@@@@@@@@M@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@O@@@@@M@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@E@@@@@@@@@@@@@@@@@@@@@@@@@@@@L@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "text = text_corpus[3]\n",
    "numbers = text_to_numbers(text)\n",
    "numbers = numbers.reshape(1,5400)\n",
    "output = model.predict(numbers)\n",
    "pred = numbers_to_text(output[0])\n",
    "print('Original :', text)\n",
    "print('Predicted :', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No luck!!! Now it's going to be just alphabatical characters!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 200\n",
    "compressed_length = 100\n",
    "\n",
    "data_file = '/Users/gursharan/Desktop/wiki_movie_plots_deduped.csv'\n",
    "\n",
    "data_reader = csv.reader(open(data_file,'r'))\n",
    "next(data_reader) #skip the header\n",
    "text_corpus = []\n",
    "for row in data_reader:\n",
    "    plot = row[-1].upper() #upper case only\n",
    "\n",
    "    text = []\n",
    "    plot_index = 0\n",
    "    while( plot_index < len(plot) and len(text) < input_length ):\n",
    "        char = plot[ plot_index ]\n",
    "        #limit to A-Z only\n",
    "        if( char>='A' and char<='Z' ):\n",
    "            text.append(char)\n",
    "        plot_index = plot_index + 1\n",
    "    \n",
    "    plot = ''.join(text)\n",
    "    if len(plot) < input_length:\n",
    "        plot = plot + 'A'*(input_length-len(plot)) #padded by A at last\n",
    "        \n",
    "    text_corpus.append(plot)\n",
    "\n",
    "def text_to_numbers( text ):\n",
    "    array = []\n",
    "    #64-90\n",
    "    for char in text:\n",
    "        val = np.zeros(26)\n",
    "        val[ord(char)-ord('A')] = 1\n",
    "        array.extend( val )\n",
    "    return np.array(array)\n",
    "\n",
    "def numbers_to_text( array ):\n",
    "    text = []\n",
    "    for total in range(input_length):\n",
    "        numbers = array[total*26:(total+1)*26]\n",
    "        text.append( chr(np.argmax(numbers)+ord('A')) )\n",
    "    return ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASTINGJUSTSECONDSANDCONSISTINGOFTWOSHOTSTHEFIRSTSHOTISSETINAWOODDURINGWINTERTHEACTORREPRESENTINGTHENVICEPRESIDENTTHEODOREROOSEVELTENTHUSIASTICALLYHURRIESDOWNAHILLSIDETOWARDSATREEINTHEFOREGROUNDHEFALL\n",
      "LASTINGJUSTSECONDSANDCONSISTINGOFTWOSHOTSTHEFIRSTSHOTISSETINAWOODDURINGWINTERTHEACTORREPRESENTINGTHENVICEPRESIDENTTHEODOREROOSEVELTENTHUSIASTICALLYHURRIESDOWNAHILLSIDETOWARDSATREEINTHEFOREGROUNDHEFALL\n"
     ]
    }
   ],
   "source": [
    "text = text_corpus[3]\n",
    "numbers = text_to_numbers(text)\n",
    "text_d = numbers_to_text(numbers)\n",
    "print(text)\n",
    "print(text_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the network\n",
    "model = keras.models.Sequential()\n",
    "model.add( keras.layers.Dense(1024, activation='relu', input_shape=(input_length*26,)) )\n",
    "model.add( keras.layers.Dense(512, activation='relu' ))\n",
    "model.add( keras.layers.Dense(compressed_length, activation='relu' ))\n",
    "model.add( keras.layers.Dense(512, activation='relu' ))\n",
    "model.add( keras.layers.Dense(1024, activation='relu' ))\n",
    "model.add( keras.layers.Dense(input_length*26, activation='relu' ))\n",
    "model.compile( loss='mae', optimizer='adadelta', metrics=['mse'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data and create train, validation, test subsets\n",
    "all_data = np.array( [ text_to_numbers(x) for x in text_corpus ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total examples :  34886\n",
      "total training examples :  27908\n",
      "total validation examples :  6978\n"
     ]
    }
   ],
   "source": [
    "data_indices = np.random.permutation(len(all_data))\n",
    "train = all_data[ data_indices[: int(len(all_data)*0.8) ] ]\n",
    "val = all_data[data_indices[int(len(all_data)*0.8):]]\n",
    "print('total examples : ', len(all_data))\n",
    "print('total training examples : ', len(train))\n",
    "print('total validation examples : ', len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27908 samples, validate on 6978 samples\n",
      "Epoch 1/10\n",
      "27908/27908 [==============================] - 154s 6ms/step - loss: 0.0386 - mse: 0.0385 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 2/10\n",
      "27908/27908 [==============================] - 152s 5ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 3/10\n",
      "27908/27908 [==============================] - 152s 5ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 4/10\n",
      "20736/27908 [=====================>........] - ETA: 38s - loss: 0.0385 - mse: 0.0385"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-09c31aa8d808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train, train, epochs=10, validation_data=(val,val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original : LASTINGJUSTSECONDSANDCONSISTINGOFTWOSHOTSTHEFIRSTSHOTISSETINAWOODDURINGWINTERTHEACTORREPRESENTINGTHENVICEPRESIDENTTHEODOREROOSEVELTENTHUSIASTICALLYHURRIESDOWNAHILLSIDETOWARDSATREEINTHEFOREGROUNDHEFALL\n",
      "Predicted : AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n"
     ]
    }
   ],
   "source": [
    "text = text_corpus[3]\n",
    "numbers = text_to_numbers(text)\n",
    "numbers = numbers.reshape(1,5200)\n",
    "output = model.predict(numbers)\n",
    "pred = numbers_to_text(output[0])\n",
    "print('Original :', text)\n",
    "print('Predicted :', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEED TO GIVE IT ANOTHER TRY!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
